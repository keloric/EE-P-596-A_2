{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 1\n",
    "### Kyle Hadley"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Simpson's Paradox\n",
    "\n",
    "Given,\n",
    "\n",
    "| Machine 1 | Wins | Losses |\n",
    "| :-: | :-: | :-: |\n",
    "| You | 40 | 60 |\n",
    "| Friend | 30 | 70 |\n",
    "\n",
    "| Machine 2 | Wins | Losses |\n",
    "| :-: | :-: | :-: |\n",
    "| You | 210 | 830 |\n",
    "| Friend | 14 | 70 |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1(a).\n",
    "\n",
    "To calculate the winning probability on a given machine, we use the following equation,\n",
    "\n",
    "$$Pr_A(W_x) = \\frac{w_x}{p_x}$$\n",
    "\n",
    "where $Pr_A(W_x)$ is the probability of person A winning on machine $x$, $w_x$ is the number of wins on machine $x$, and $p_x$ is the number of games played on machine $x$.\n",
    "\n",
    "Using the above equation, we can calculate the probability of my friend and I winning on each machine and output.\n",
    "\n",
    "The probability of myself winning on Machines 1 and 2 are,\n",
    "\n",
    "$$Pr_{me}(W_1) = \\frac{40}{40 + 60} = 0.4$$\n",
    "$$Pr_{me}(W_2) = \\frac{210}{210 + 830} \\approx 0.202$$\n",
    "\n",
    "The probability of my friend winning on Machines 1 and 2 are,\n",
    "\n",
    "$$Pr_{friend}(W_1) = \\frac{30}{30 + 70} = 0.3$$\n",
    "$$Pr_{friend}(W_2) = \\frac{14}{14 + 70} \\approx 0.167$$\n",
    "\n",
    "On both machines and given the dataset provided, **I** am more likely to win on both Machine 1 and Machine 2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1(b).\n",
    "\n",
    "To calculate the winning probability in the entire casino, we use the following equation,\n",
    "\n",
    "$$Pr_A(W) = \\sum_{x=1}^n \\left ( Pr_A(W_x) * \\frac{p_x}{p_T} \\right )$$\n",
    "\n",
    "where $Pr_A(W)$ is the probability of person A winning in the casino, $p_T$ is total number of games played in the casino, $p_x$ is the number of games played on a given machine $x$, and $n$ is the total number of machines played while in the casino.\n",
    "\n",
    "Using the above equation, we can calculate the probability of my friend and I winning in the casino.\n",
    "\n",
    "The probability of myself winning is,\n",
    "\n",
    "$$Pr_{me}(W) = 0.400 * \\frac{100}{100 + 1040} + 0.202 * \\frac{1040}{100 + 1040} \\approx 0.219$$\n",
    "\n",
    "The probability of my friend winning on Machines 1 and 2 are,\n",
    "\n",
    "$$Pr_{friend}(W) = 0.300 * \\frac{100}{100 + 84} + 0.167 * \\frac{84}{100 + 84} \\approx 0.239$$\n",
    "\n",
    "Given the dataset provided, **my friend** is more likely to win in the casino."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1(c).\n",
    "\n",
    "In looking at the data, we can see that my friend is more likely to win in the casino despite having a lower probability of winning on either machine 1 or machine 2 - when assessed individually.\n",
    "\n",
    "When reviewing the equation from part (b), we see that the total probability of winning in the casino is a weight averaged of the probability of winning on a machine machine where the average function is the number of games played on a machine.\n",
    "\n",
    "For my games played, I played a significantly higher number of games played on the machine with the lower probability of winning. For my friend's games played, he played a higher number of games played on the machine with the higher probability of winning. Thus, his total winning percentage will be closer to the winning percentage from machine 1 (which is the higher percentage) and my winning percentage will be closer to the winning percentage from machine 2 (which is the lower percentage)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1(d).\n",
    "\n",
    "The conclusions of (a) and (b) could be the same when $Pr_{friend}(W) \\leq Pr_{me}(W) \\approx 0.219$. By inspection, we can see that we need to have my friend play more games on machine 2 to decrease his winning probability; thus we will only let him keep playing on machine 2.\n",
    "\n",
    "Solving the equality given above, and assuming that the previously winning percentages for myself on both machines and my friend on machine 1 are still valid,\n",
    "\n",
    "$$Pr_{friend}(W) = \\sum_{x=1}^n \\left ( Pr_A(W_x) * \\frac{p_x}{p_T} \\right ) = Pr_{me}(W)$$\n",
    "$$Pr_{friend}(W_1) * \\frac{p_1}{p_T} + Pr_{friend}(W_2) * \\frac{p_2}{p_T} = Pr_{me}(W)$$\n",
    "$$\\frac{Pr_{friend}(W_1)p_1 + Pr_{friend}(W_2)p_2}{p_T} = Pr_{me}(W)$$\n",
    "\n",
    "Given that $p_T = p_1 + p_2$ and solving for $p_2$ (using approximations),\n",
    "\n",
    "$$p_2 = p_1 \\left(\\frac{Pr_{me}(W) - Pr_{friend}(W_1)}{Pr_{friend}(W_2) - Pr_{me}(W)}\\right)$$\n",
    "$$p_2 = 100 \\left(\\frac{0.219 - .3}{.167 - .219}\\right)$$\n",
    "$$p_2 \\approx 155.76$$\n",
    "\n",
    "Thus, we see that in order for conclusions of (a) and (b) to be true (i.e. I have the highest winning percentage on both machines and in the casino), my friend would have to have played at least $156$ games on machine 2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Linear Algebra Refresher\n",
    "\n",
    "Given $a_1 = (1, 0)$, $a_2 = (0,1)$, $b_1 = (2,0)$, and $b_2 = (3,2)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2(a).\n",
    "\n",
    "We can solve for the matrix $W$ by solving the relationships in which $W$ transforms $a_1$ to $b_1$, and $a_2$ to $b_2$,\n",
    "\n",
    "$$a_1W = b_1$$\n",
    "$$a_2W = b_2$$\n",
    "\n",
    "We define $W$ as $W = \\begin{bmatrix}W_{11} & W_{12} \\\\ W_{21} & W_{22}\\end{bmatrix}$, since we given that it is a $2\\times 2$ matrix.\n",
    "\n",
    "Solving the first equation, we find\n",
    "\n",
    "$$a_1W = b_1$$\n",
    "$$\\begin{bmatrix}1 & 0\\end{bmatrix}\\begin{bmatrix}W_{11} & W_{12} \\\\ W_{21} & W_{22}\\end{bmatrix} = \\begin{bmatrix}2 & 0\\end{bmatrix}$$\n",
    "$$\\begin{bmatrix}W_{11} & W_{21} \\end{bmatrix} = \\begin{bmatrix}2 & 0\\end{bmatrix}$$\n",
    "\n",
    "Solving the second equation, we find\n",
    "\n",
    "$$a_2W = b_2$$\n",
    "$$\\begin{bmatrix}0 & 1\\end{bmatrix}\\begin{bmatrix}W_{11} & W_{12} \\\\ W_{21} & W_{22}\\end{bmatrix} = \\begin{bmatrix}3 & 2\\end{bmatrix}$$\n",
    "$$\\begin{bmatrix}W_{12} & W_{22} \\end{bmatrix} = \\begin{bmatrix}3 & 2\\end{bmatrix}$$\n",
    "\n",
    "Thus, we can define a matrix $W = \\begin{bmatrix}2 & 3 \\\\ 0 & 2\\end{bmatrix}$ such that $W$ transforms $a_1$ to $b_1$, and $a_2$ to $b_2$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2(b).\n",
    "\n",
    "We can define a rotation matrix $V$ such that it rotates clockwise by $\\alpha$ degrees as follows,\n",
    "\n",
    "$$V = \\begin{bmatrix} \\cos{(-\\alpha)} & -\\sin{(-\\alpha)} \\\\ \\sin{(-\\alpha)} & \\cos{(-\\alpha)} \\end{bmatrix}$$\n",
    "\n",
    "where $\\alpha = \\tan^{-1}{(2)}$.\n",
    "\n",
    "We can define a scaling matrix $\\Sigma$ such that it scales the x-axis by 4 as follows,\n",
    "\n",
    "$$\\Sigma = \\begin{bmatrix} 4 & 0 \\\\ 0 & 1 \\end{bmatrix}$$\n",
    "\n",
    "We can define a rotation matrix $U$ such that it rotates clockwise by $\\beta$ degrees as follows,\n",
    "\n",
    "$$U = \\begin{bmatrix} \\cos{(\\beta)} & -\\sin{(\\beta)} \\\\ \\sin{(\\beta)} & \\cos{(\\beta)} \\end{bmatrix}$$\n",
    "\n",
    "where $\\beta = \\tan^{-1}{(\\frac{1}{2})}$.\n",
    "\n",
    "Multipling the three matrices together, namely $U\\Sigma V$, symbolically the resulting matrix is as follows,\n",
    "\n",
    "$$U\\Sigma V = \\begin{bmatrix} \\cos{(-\\alpha)} & -\\sin{(-\\alpha)} \\\\ \\sin{(-\\alpha)} & \\cos{(-\\alpha)} \\end{bmatrix} \\cdot \\begin{bmatrix} 4 & 0 \\\\ 0 & 1 \\end{bmatrix} \\cdot \\begin{bmatrix} \\cos{(\\beta)} & -\\sin{(\\beta)} \\\\ \\sin{(\\beta)} & \\cos{(\\beta)} \\end{bmatrix}$$\n",
    "\n",
    "$$U \\Sigma V = \\begin{bmatrix} 4 \\cos{(-\\alpha)} & -\\sin{(-\\alpha)} \\\\ 4 \\sin{(-\\alpha)} & \\cos{(-\\alpha)} \\end{bmatrix} \\cdot \\begin{bmatrix} \\cos{(\\beta)} & -\\sin{(\\beta)} \\\\ \\sin{(\\beta)} & \\cos{(\\beta)} \\end{bmatrix}$$\n",
    "\n",
    "$$U \\Sigma V = \\begin{bmatrix} 4 \\cos{(-\\alpha)} \\cos{(\\beta)} -\\sin{(-\\alpha)} \\sin{(\\beta)} & -4 \\cos{(-\\alpha)} \\sin{(\\beta)} -\\sin{(-\\alpha)} \\cos{(\\beta)} \\\\ 4 \\sin{(-\\alpha)} \\cos{(\\beta)} +\\cos{(-\\alpha)} \\sin{(\\beta)} & -4 \\sin{(-\\alpha)} \\sin{(\\beta)} +\\cos{(-\\alpha)} \\cos{(\\beta)} \\end{bmatrix}$$\n",
    "\n",
    "When we solve the matrix (as done below in Python) with $\\alpha = \\tan^{-1}{(2)}$ and $\\beta = \\tan^{-1}{(\\frac{1}{2})}$, we find that $U \\Sigma V = \\begin{bmatrix}2 & 3 \\\\ 0 & 2\\end{bmatrix} = W$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[[2.00000000e+00 3.00000000e+00]\n [2.22044605e-16 2.00000000e+00]]\n"
     ]
    }
   ],
   "source": [
    "# Define angles alpha and beta\n",
    "a = np.arctan(2)\n",
    "b = np.arctan(1/2)\n",
    "\n",
    "# Define matrix V, E, and U\n",
    "V = np.array([[np.cos(-a), -np.sin(-a)], [np.sin(-a), np.cos(-a)]])\n",
    "E = np.array([[4,0],[0,1]])\n",
    "U = np.array([[np.cos(b), -np.sin(b)], [np.sin(b), np.cos(b)]])\n",
    "\n",
    "# Calculate and print the summation of the 3 transformation matrics.\n",
    "UEV = U.dot(E.dot(V))\n",
    "print(UEV)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2(c).\n",
    "\n",
    "We start by defining the matrix $W^TW$ as\n",
    "\n",
    "$$W^TW = \\begin{bmatrix}2 & 3 \\\\ 0 & 2\\end{bmatrix} \\cdot \\begin{bmatrix}2 & 0 \\\\ 3 & 2\\end{bmatrix} = \\begin{bmatrix}4 & 6 \\\\ 6 & 13\\end{bmatrix}$$\n",
    "\n",
    "To calculate the eigenvalues, we use the equation $|W^TW - \\lambda I| = 0$ and solve for $\\lambda$.\n",
    "\n",
    "$$\\left|W^TW - \\lambda I\\right| = 0$$\n",
    "$$\\left|\\begin{bmatrix}4 & 6 \\\\ 6 & 13\\end{bmatrix} - \\begin{bmatrix}\\lambda & 0 \\\\ 0 & \\lambda\\end{bmatrix}\\right| = 0$$\n",
    "$$\\left|\\begin{bmatrix}4-\\lambda & 6 \\\\ 6 & 13-\\lambda \\end{bmatrix} \\right| = 0$$\n",
    "$$(4-\\lambda)(13-\\lambda)=0$$\n",
    "$$\\lambda^2-17\\lambda+16=0$$\n",
    "$$(\\lambda-1)(\\lambda-16)=0$$\n",
    "\n",
    "Thus, we find that $\\lambda_1 = 1$ and $\\lambda_2 = 16$.\n",
    "\n",
    "Next, we can find corresponding eigenvectors using the equation $W^TW v_x = \\lambda_x v_x$ where $v_x$ is the eigenvector for $\\lambda_x$.\n",
    "\n",
    "For $\\lambda_1 = 1$,\n",
    "\n",
    "$$W^TW v_1 = \\lambda_1 v_1$$\n",
    "$$(W^TW -\\lambda_1) v_1 = 0$$\n",
    "$$ \\begin{bmatrix}4-\\lambda_1 & 6 \\\\ 6 & 13-\\lambda_1 \\end{bmatrix} v_1 = 0$$\n",
    "$$ \\begin{bmatrix}3 & 6 \\\\ 6 & 12 \\end{bmatrix} v_1 = 0$$\n",
    "\n",
    "From this equation, we find the relationship\n",
    "\n",
    "$$3 v_{1,1} + 6 v_{1,2} = 0$$\n",
    "$$v_{1,1} = -2 v_{1,2}$$\n",
    "\n",
    "So, we can determine that the eigenvector for $\\lambda_1$ is any non-zero multiple of $(-2, 1)$.\n",
    "\n",
    "For $\\lambda_2 = 16$,\n",
    "\n",
    "$$W^TW v_2 = \\lambda_2 v_2$$\n",
    "$$(W^TW -\\lambda_2) v_2 = 0$$\n",
    "$$ \\begin{bmatrix}4-\\lambda_2 & 6 \\\\ 6 & 13-\\lambda_2 \\end{bmatrix} v_2 = 0$$\n",
    "$$ \\begin{bmatrix}-12 & 6 \\\\ 6 & -3 \\end{bmatrix} v_2 = 0$$\n",
    "\n",
    "From this equation, we find the relationship\n",
    "\n",
    "$$-12 v_{2,1} + 6 v_{2,2} = 0$$\n",
    "$$2 v_{2,1} = v_{2,2}$$\n",
    "\n",
    "So, we can determine that the eigenvector for $\\lambda_2$ is any non-zero multiple of $(1, 2)$.\n",
    "\n",
    "Thus, we find that the eigenvalues are $\\lambda_1 = 1$ and $\\lambda_2 = 16$ with corresponding eigenvectors $v_1 = (-2, 1)$ and $v_2 = (1, 2)$. This is verified below in the python snippet.\n",
    "\n",
    "If we were to apply the transformation $W$ to every point on the unit circle, we would see the circle stretched along the vector $b_2$ by a factor of $4$.\n",
    "\n",
    "It seems that the eigenvalues represent the stretch factor along the axeses defined by the eigenvectors. For example, a stretch factor of $\\sqrt{\\lambda_1}$ ($4$) is applied along the axis defined by $v_1$ ($(1, 2)$)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[[ 4  6]\n [ 6 13]]\n(array([ 1., 16.]), array([[-0.89442719, -0.4472136 ],\n       [ 0.4472136 , -0.89442719]]))\n"
     ]
    }
   ],
   "source": [
    "# Define our matrix W, print out the matrix W^T*W\n",
    "W = np.array([[2, 3],[0, 2]])\n",
    "print(W.transpose().dot(W))\n",
    "\n",
    "# Calculate and print the eigenvalues and eigenvecotrs for the matrix W^T*W for verification of hand calculations\n",
    "print(np.linalg.eig(W.transpose().dot(W)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2(d).\n",
    "\n",
    "The determinant of W is calculated as $det(W) = (4)(13) - (6)(6) = 4$.\n",
    "\n",
    "The area of the shape transformed from the unit circle is equal to $4\\pi$. It can then by hypothesized that area of a shape when transformed by a $X$ is scaled by a factor equal to the determinant of $X$.\n",
    "\n",
    "Given the hypothesis that the area of a shape when transformed by a given matrix is scaled by a factor equivalent to the determinant of the given matrix, and given that applying a transformation $AB$ to a shape is equivalent to applying the transformation $A$ then $B$, it must be that the $det(AB) = det(A)det(B)$. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Programming Problem: Density Estimation and Multivariate Gaussian\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3(a).\n",
    "\n",
    "Using the provided code, I generated a 1000 points as captured within $X$ as sampled from a multivariante Gaussian distribution. A plot of these 1000 points are shown in the figure below.\n",
    "\n",
    "![Figure 3(a) - Plot of X](graph_3_a.png)\n",
    "\n",
    "We can estimate the mean and covariance of $X$ using *numpy.mean* and *numpy.cov*. Using these functions we find the mean and covariance of $X$ to be:\n",
    "\n",
    "Mean of $X$: $\\begin{bmatrix}0.0104 & 0.0612\\end{bmatrix}$\n",
    "\n",
    "Covariance of $X$:\n",
    "\n",
    "$\\begin{bmatrix}4.2780 & 2.4099 & 2.0527 & ... & 2.9792 & 2.196 & 3.0690 \\\\\n",
    "... & & & & & & ... \\\\\n",
    "3.0690 & 1.7288 & 1.4726 & ... & 2.1373 & 1.5755 & 2.2017\\end{bmatrix}$\n",
    "\n",
    "*Note: The covariance matrix is the size ${1000 x 1000}$, thus only a sub-sample is reported out.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3(b).\n",
    "\n",
    "A plot of the histogram for x-coordinates and y-coordinates of $X$ are shown in the figure below.\n",
    "\n",
    "![Figure 3(b) - Histogram of x-coordinates and y-coordinates of X](graph_3_b.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3(c).\n",
    "\n",
    "From the histogram, we can see that the x-coordinates follow a seemingly normal Gaussian distribution. Thus, we can estimate a mean and variance using the following equation:\n",
    "\n",
    "$$\\bar{x} = \\frac{1}{n} \\sum_{i=0}^n (x_i * h_i)$$\n",
    "\n",
    "where $n$ is the total number of bins in our histogram, $x_i$ is the midpoint of the bin with respect to $x$, and $h_i$ is the height of the bin (i.e. the count within the specified bin).\n",
    "\n",
    "We can estimate the variance ($sigma^2$) using the following equation:\n",
    "\n",
    "$$\\sigma^2 = \\frac{1}{n} \\sum_{i=0}^n (x_i - \\bar{x})^2$$\n",
    "\n",
    "where $n$ is the total number of bins in our histogram, $x_i$ is the midpoint of the bin with respect to $x$.\n",
    "\n",
    "Given these equations, we can solve for these values in Python such that $\\bar{x} = 0.013$ and $\\sigma_x^{2} = 1.0678$.\n",
    "\n",
    "From the histogram, we can also see that the y-coordinates follow a seemingly normal Gaussian distribution. Thus we can use the same equations, but insteading solve with respect to the y-coordinate. We find that $\\bar{y} = 0.07325$ and $\\sigma_y^2 = 5.0321$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3(d).\n",
    "\n",
    "Using the mean and covariance values calculated, a new set of 1000 points using a 1D Gaussian distribution for both x and y-coordinates is generated. The plot generated is shown below.\n",
    "\n",
    "When comparing the original 1000 points and the new distribution, the original distribution skewed. We can estimate the it is skewed along the line $y = 3x+1$ based on inferences seen in part (e) and (f).\n",
    "\n",
    "This lack of skewing in our new dataset is driven by the way we calcualte our points within our new dataset. When we calculate our normal and variances, we decouple the relationship between our x-coordinate and y-coordinates. Rather than maintaing the relationship in which it is more likely to have a larger y-coordinate with a higher x-coordinate, we are simply capturing the mean and variance of our x and y independent of one another. Thus, when we re-couple the two values we simply see a clumping of our point about the $x=0$ and $y=0$ axises.\n",
    "\n",
    "![Figure 3(d) - Plot of newly generated points using means and covariances from part (c)](graph_3_d.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3(e).\n",
    "\n",
    "Generating the line segment $y=3x+1$ and plotting this line with respect to the dataset $X$ is shown in the plot below.\n",
    "\n",
    "![Figure 3(e).1 - Plot of line segment y=3x+1 with initial dataset X](graph_3_e.png)\n",
    "\n",
    "To calculate the projection of $X$ onto the line $y=3x+1$, we can use the equation for projection using vector notation as\n",
    "\n",
    "$$proj_{\\vec{y}} \\vec{X} = \\frac{\\vec{y} \\cdot \\vec{X}}{\\vec{y} \\cdot \\vec{y}} \\vec{y} + y_{origin}$$\n",
    "\n",
    "where $\\vec{y} = (1, 3)$, $y_{origin} = (0, 1)$, and $\\vec{X}$ is the vector notation for each point in our data.\n",
    "\n",
    "Using this equation, we project all of $X$ onto the line $y$ and can demonstrate that this projection is successful by plotting a subset of the data (30 points) as shown below.\n",
    "\n",
    "![Figure 3(e).2 - Plot of the projection of X onto y (initial X set and y included for reference)](graph_3_e_2.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3(f).\n",
    "\n",
    "We can now plot the histogram of the projection points, $X_proj$, as shown in the plot below.\n",
    "\n",
    "![Figure 3(f) - Histogram of x-coordinates X-projection](graph_3_f.png)\n",
    "\n",
    "Based on the histogram, we can see that the points follow a normal Gaussian distribution as seen in part (c). Given those equations, we can solve for mean and variance in Python such that $\\bar{x}_{proj} = 0.015$ and $\\sigma_{x, proj}^{2} = 0.589279$."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9-final"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}