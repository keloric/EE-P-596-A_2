{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 4\n",
    "### Kyle Hadley"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. PCA via Successive Deflation\n",
    "\n",
    "*Note: Worked problem with Charlie and Joaquin from class on this problem.*"
   ]
  },
  {
   "source": [
    "### (a)\n",
    "\n",
    "For the covariance of the deflated matrix, we are given the relationship $\\tilde{X}^T = (I - v_1v_1^T)X^T$. From this relationship, we know that $\\tilde{X} = X(I - v_1v_1^T)$.\n",
    "\n",
    "From these relationships, we start with our covariance of the deflated matrix such that,\n",
    "\n",
    "$$\\tilde{C} = \\frac{1}{n} \\tilde{X}^T\\tilde{X}$$\n",
    "\n",
    "Substituting our relationships for $\\tilde{X}^T$ and $\\tilde{X}$,\n",
    "\n",
    "$$\\tilde{C} = \\frac{1}{n} (I - v_1v_1^T)X^TX(I - v_1v_1^T)$$\n",
    "\n",
    "We can substitute $\\frac{1}{n}X^TX = C$ such that\n",
    "\n",
    "$$\\tilde{C} = (I - v_1v_1^T)C(I - v_1v_1^T)$$\n",
    "$$\\tilde{C} = C - v_1v_1^TC - Cv_1v_1^T + v_1v_1^TCv_1v_1^T$$\n",
    "\n",
    "Substituing our relationship $Cv_1 = \\lambda_1v_1$ and given that $\\lambda$ is a constant,\n",
    "\n",
    "$$\\tilde{C} = C - v_1v_1^TC - \\lambda_1 v_1v_1^T + v_1v_1^T\\lambda_1 v_1v_1^T$$\n",
    "$$\\tilde{C} = C - v_1v_1^TC - \\lambda_1 v_1v_1^T + \\lambda_1 v_1v_1^Tv_1v_1^T$$\n",
    "\n",
    "Also, given our orthonormality relationship we know that $v_1^Tv_1 = 1$; thus,\n",
    "\n",
    "$$\\tilde{C} = C - v_1v_1^TC - \\lambda_1 v_1v_1^T + \\lambda_1 v_1v_1^T$$\n",
    "$$\\tilde{C} = C - v_1v_1^TC$$\n",
    "\n",
    "We can take a \"double\" transpose of our left-most term (i.e. $a = (a^T)^T$); thus,\n",
    "\n",
    "$$\\tilde{C} = C - ((v_1v_1^TC)^T)^T$$\n",
    "$$\\tilde{C} = C - (C^Tv_1v_1^T)^T$$\n",
    "\n",
    "From our relationship for $C$, we can see that $C = C^T$ ($C = \\frac{1}{n}X^TX = C^T$); thus,\n",
    "\n",
    "$$\\tilde{C} = C - (Cv_1v_1^T)^T$$\n",
    "\n",
    "Applying our relationship again of $Cv_1 = \\lambda_1 v_1$ and $C = \\frac{1}{n}X^TX$,\n",
    "\n",
    "$$\\tilde{C} = \\frac{1}{n}X^TX - (\\lambda_1 v_1v_1^T)^T$$\n",
    "$$\\tilde{C} = \\frac{1}{n}X^TX - \\lambda_1 v_1v_1^T$$"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### (b)\n",
    "\n",
    "For a $j \\neq 1$ and $v_j$ as a principle eigvenvector of $C$, we can show that $v_j$ is also a principal eigenvector of $\\tilde{C}$ with the same eigenvalue $\\lambda_j$.\n",
    "\n",
    "Given $\\tilde{C} = \\frac{1}{n}X^TX - \\lambda_1 v_1v_1^T$, we right-multiply both sides by $v_j$,\n",
    "\n",
    "$$\\tilde{C}v_j = \\left(\\frac{1}{n}X^TX - \\lambda_1 v_1v_1^T\\right) v_j$$\n",
    "$$\\tilde{C}v_j = \\frac{1}{n}X^TXv_j - \\lambda_1 v_1v_1^Tv_j$$\n",
    "\n",
    "Given our orthonormality relationship, we know that if $j \\neq 1$ then $v_1^Tv_j = 0$; thus,\n",
    "\n",
    "$$\\tilde{C}v_j = \\frac{1}{n}X^TXv_j - \\lambda_1 v_1(0)$$\n",
    "$$\\tilde{C}v_j = \\frac{1}{n}X^TXv_j$$\n",
    "\n",
    "Substituting $\\frac{1}{n}X^TX = C$,\n",
    "\n",
    "$$\\tilde{C}v_j = Cv_j = \\lambda_j v_j$$\n",
    "\n",
    "Thus, we can see that $v_j$ is also a principal eigenvector of $\\tilde{C}$ with the same eigenvalue $\\lambda_j$."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### (c)\n",
    "\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### (d)\n",
    "\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Locality Sensitive Hashing"
   ]
  },
  {
   "source": [
    "### (a)\n",
    "\n",
    "In order to avoid the 3rd condition where the magical oracle is unstable, we set $c = 1$ such that $r = cr$. This will ensure that we avoid the unstable condition when requesting a nearest neighbor.\n",
    "\n",
    "After setting $c=1$, we can perform iterative queries by starting with an arbitrary $r_0$. Given an $r_0$ we can ask the oracle for the nearest neighbor of a query point $q$.\n",
    "\n",
    "If the oracle returns a point $x'$, then we will reduce our $r_0$ by half (rounded down) and perform a new query with our new $r_1$ (i.e. half the original $r_0$). If the oracle still returns a point $x'$, then we continue to reduce our $r_i$ by half (as long as it's possible with integer values) until we've reached a point where the oracle finds nothing. Once the oracle finds nothing, then we take the average of our $r_{i-1}$ from the previous iteration and the latest $r_i$ for $r_{i+1}$. We perform this \"yo-yo\"-ing until we reach a point where we know that there is no smaller $r$ that yields an $x'$.\n",
    "\n",
    "We perform a similar series of steps if the oracle doesn't return a point $x'$ with our initial $r_0$ but instead set $r_{i+1} = 2r_i$ until the oracle does return an $x'$. Then we begin the same \"yo-yo\"ing as described above until we reach a set $r$."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### (b)\n",
    "\n",
    "The lower bound for the probability that $h$ maps $x_i$ and $x_j$ to the same value is a function of the number of common values within $x_i$ and $x_j$ at the same indices. While we don't have a function or value for the common values, we can use the Hamming distance as this represents where $x_i$ and $x_j$ have differing values at various positions within the vectors.\n",
    "\n",
    "Given that $d(x_i, x_j) \\leq r$, we know that the lower bound for common values (i.e. $h(x_i) = h(x_j)$) is when $d(x_i, x_j) = r$; thus, we can describe the probability of $h(x_i) = h(x_j)$ as,\n",
    "\n",
    "$$p_1 = Pr(h(x_i) = h(x_j)) = 1 - \\frac{r}{m}$$\n",
    "\n",
    "where $m$ is the size of the binary vectors $x_i$ and $x_j$.\n",
    "\n",
    "Given $d(x_i, x_j) \\geq r$, we know that upper bound for common values is when $d(x_i, x_j) = cr$; thus, we can describe the probability of $h(x_i) = h(x_j)$ as,\n",
    "\n",
    "$$p_2 = Pr(h(x_i) = h(x_j)) = 1 - \\frac{cr}{m}$$\n",
    "\n",
    "The inequality relationship between $p_1$ and $p_2$ is $p_2 \\leq p_1$.\n",
    "\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### (c)\n",
    "\n",
    "Given that $g(x_i) = (h_1(x_i), h_2(x_i), \\ldots , h_k(x_i))$, we can surmise that the probability of $g(x_i) = g(x_j)$ is equivalent to the combined probability of $h_1(x_i) = h_1(x_j)$, $h_2(x_i) = h_2(x_j)$, ..., $h_k(x_i) = h_k(x_j)$; thus,\n",
    "\n",
    "$$Pr(g(x_i) = g(x_j)) = Pr(h_1(x_i) = h_1(x_j)) \\times Pr(h_2(x_i) = h_2(x_j)) \\times \\ldots \\times Pr(h_k(x_i) = h_k(x_j))$$\n",
    "\n",
    "Substituting our $p_1$ for our lower bound condition, the lower bound of our probability is\n",
    "\n",
    "$$Pr(g(x_i) = g(x_j)) = p_1 \\times p_1 \\times \\ldots \\times p_1$$\n",
    "$$Pr(g(x_i) = g(x_j)) = p_1^k$$\n",
    "\n",
    "Substituting our $p_2$ for our lower bound condition, the lower bound of our probability is\n",
    "\n",
    "$$Pr(g(x_i) = g(x_j)) = p_2 \\times p_2 \\times \\ldots \\times p_2$$\n",
    "$$Pr(g(x_i) = g(x_j)) = p_2^k$$"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### (d)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### (e)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### (f)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Programming Problem: Lasso\n",
    "\n",
    "*Note: Worked on this problem with Niraj and Charlie from class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9-final"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}